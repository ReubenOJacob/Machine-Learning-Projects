{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uA1B0DSeEUy"
      },
      "source": [
        "# Lab:  Logistic Regression for Gene Expression Data\n",
        "\n",
        "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In addition to the concepts in [breast cancer demo](./breast_cancer.ipynb), you will learn to:\n",
        "* Handle missing data\n",
        "* Perform multi-class logistic classification\n",
        "* Create a confusion matrix\n",
        "* Use L1-regularization for improved estimation in the case of sparse weights (Grad students only)\n",
        "\n",
        "## Background\n",
        "\n",
        "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
        "\n",
        "The data in this lab comes from:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
        "\n",
        "In this data, mice were characterized by three properties:\n",
        "* Whether they had down's syndrome (trisomy) or not\n",
        "* Whether they were stimulated to learn or not\n",
        "* Whether they had a drug memantine or a saline control solution.\n",
        "\n",
        "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRT797vheEUz"
      },
      "source": [
        "## Load the Data\n",
        "\n",
        "We begin by loading the standard modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7D5o5aIVeEUz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbi3yIcdeEU0"
      },
      "source": [
        "Use the `pd.read_excel` command to read the data from \n",
        "\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
        "\n",
        "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z4mBw38feEU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "4cbd81a6-ce3a-43ad-d125-367e2394b4c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
              "MouseID                                                                         \n",
              "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
              "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
              "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
              "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
              "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
              "\n",
              "         pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
              "MouseID                                 ...                                  \n",
              "309_1     2.373744  0.232224  1.750936  ...  0.108336  0.427099   0.114783   \n",
              "309_2     2.292150  0.226972  1.596377  ...  0.104315  0.441581   0.111974   \n",
              "309_3     2.283337  0.230247  1.561316  ...  0.106219  0.435777   0.111883   \n",
              "309_4     2.152301  0.207004  1.595086  ...  0.111262  0.391691   0.130405   \n",
              "309_5     2.134014  0.192158  1.504230  ...  0.110694  0.434154   0.118481   \n",
              "\n",
              "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
              "MouseID                                                                       \n",
              "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
              "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
              "309_3    0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
              "309_4    0.147444  0.146901  1.700563   Control  Memantine       C/S  c-CS-m  \n",
              "309_5    0.140314  0.148380  1.839730   Control  Memantine       C/S  c-CS-m  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca620797-48dc-4289-a69e-cc5691eb132a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DYRK1A_N</th>\n",
              "      <th>ITSN1_N</th>\n",
              "      <th>BDNF_N</th>\n",
              "      <th>NR1_N</th>\n",
              "      <th>NR2A_N</th>\n",
              "      <th>pAKT_N</th>\n",
              "      <th>pBRAF_N</th>\n",
              "      <th>pCAMKII_N</th>\n",
              "      <th>pCREB_N</th>\n",
              "      <th>pELK_N</th>\n",
              "      <th>...</th>\n",
              "      <th>pCFOS_N</th>\n",
              "      <th>SYP_N</th>\n",
              "      <th>H3AcK18_N</th>\n",
              "      <th>EGR1_N</th>\n",
              "      <th>H3MeK4_N</th>\n",
              "      <th>CaNA_N</th>\n",
              "      <th>Genotype</th>\n",
              "      <th>Treatment</th>\n",
              "      <th>Behavior</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MouseID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309_1</th>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.747193</td>\n",
              "      <td>0.430175</td>\n",
              "      <td>2.816329</td>\n",
              "      <td>5.990152</td>\n",
              "      <td>0.218830</td>\n",
              "      <td>0.177565</td>\n",
              "      <td>2.373744</td>\n",
              "      <td>0.232224</td>\n",
              "      <td>1.750936</td>\n",
              "      <td>...</td>\n",
              "      <td>0.108336</td>\n",
              "      <td>0.427099</td>\n",
              "      <td>0.114783</td>\n",
              "      <td>0.131790</td>\n",
              "      <td>0.128186</td>\n",
              "      <td>1.675652</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_2</th>\n",
              "      <td>0.514617</td>\n",
              "      <td>0.689064</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>2.789514</td>\n",
              "      <td>5.685038</td>\n",
              "      <td>0.211636</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>2.292150</td>\n",
              "      <td>0.226972</td>\n",
              "      <td>1.596377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104315</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.111974</td>\n",
              "      <td>0.135103</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>1.743610</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_3</th>\n",
              "      <td>0.509183</td>\n",
              "      <td>0.730247</td>\n",
              "      <td>0.418309</td>\n",
              "      <td>2.687201</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>0.209011</td>\n",
              "      <td>0.175722</td>\n",
              "      <td>2.283337</td>\n",
              "      <td>0.230247</td>\n",
              "      <td>1.561316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.106219</td>\n",
              "      <td>0.435777</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.133362</td>\n",
              "      <td>0.127431</td>\n",
              "      <td>1.926427</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_4</th>\n",
              "      <td>0.442107</td>\n",
              "      <td>0.617076</td>\n",
              "      <td>0.358626</td>\n",
              "      <td>2.466947</td>\n",
              "      <td>4.979503</td>\n",
              "      <td>0.222886</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>2.152301</td>\n",
              "      <td>0.207004</td>\n",
              "      <td>1.595086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111262</td>\n",
              "      <td>0.391691</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>0.146901</td>\n",
              "      <td>1.700563</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_5</th>\n",
              "      <td>0.434940</td>\n",
              "      <td>0.617430</td>\n",
              "      <td>0.358802</td>\n",
              "      <td>2.365785</td>\n",
              "      <td>4.718679</td>\n",
              "      <td>0.213106</td>\n",
              "      <td>0.173627</td>\n",
              "      <td>2.134014</td>\n",
              "      <td>0.192158</td>\n",
              "      <td>1.504230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.434154</td>\n",
              "      <td>0.118481</td>\n",
              "      <td>0.140314</td>\n",
              "      <td>0.148380</td>\n",
              "      <td>1.839730</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca620797-48dc-4289-a69e-cc5691eb132a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca620797-48dc-4289-a69e-cc5691eb132a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca620797-48dc-4289-a69e-cc5691eb132a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO 1\n",
        "#   df = pd.read_excel(...)\n",
        "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00342/' + 'Data_Cortex_Nuclear.xls', index_col = 0)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE-BK6CjeEU0"
      },
      "source": [
        "This data has missing values.  The site:\n",
        "\n",
        "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
        "\n",
        "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WVm8fXpCeEU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f010a5a1-d449-41b5-9d03-aa6ea81f89e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# TODO 2\n",
        "#  df1 = ...\n",
        "df1 = df.fillna(df.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY6Bc9x3eEU0"
      },
      "source": [
        "## Binary Classification for Down's Syndrome\n",
        "\n",
        "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lLwfAN1feEU0"
      },
      "outputs": [],
      "source": [
        "# TODO 3\n",
        "#   y = ...\n",
        "dfgenes = df1['Genotype'].values\n",
        "values, y = np.unique(dfgenes, return_inverse = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVx_znWdeEU1"
      },
      "source": [
        "As predictors, get all but the last four columns of the dataframes.  Store the data matrix into `X` and the names of the columns in `xnames`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MzjV2dwdeEU1"
      },
      "outputs": [],
      "source": [
        "# TODO 4\n",
        "#   xnames = ...\n",
        "#   X = ...\n",
        "xnames = df1.columns[:-4]\n",
        "X = np.array(df1[xnames].values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1VY9LHeEU1"
      },
      "source": [
        "Split the data into training and test with 30% allocated for test.  You can use the train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f0RCg5ZSeEU1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Use : shuffle=True, random_state=3 so we all can have same split.\n",
        "# TODO 5: \n",
        "#   Xtr, Xts, ytr, yts = ...\n",
        "Xtr,Xts,ytr,yts = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=3) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp3W9uJjeEU1"
      },
      "source": [
        "Scale the data with the `StandardScaler`.  Store the scaled values in `Xtr1` and `Xts1`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vnPbjFxDeEU1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# TODO 6\n",
        "#  Xtr1 = ...\n",
        "#  Xts1 = ...\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Xtr1 = scaler.fit_transform(Xtr)\n",
        "Xts1 = scaler.transform(Xts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD68GubdeEU1"
      },
      "source": [
        "Create a `LogisticRegression` object `logreg` and `fit` on the scaled training data.  Set the regularization level to `C=1e5` and use the optimizer `solver=liblinear`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m70WPAAyeEU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16610e26-36d7-447c-b79c-93e133497df7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# TODO 7\n",
        "#   logreg = ...\n",
        "logreg = linear_model.LogisticRegression(C=1e5, solver = 'liblinear')\n",
        "logreg.fit(Xtr1, ytr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKAjDuH3eEU1"
      },
      "source": [
        "Measure the accuracy of the classifer on test data.  You should get around 94%.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y2IyauuJeEU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61dabed8-f057-40c9-ed54-b34563eba173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the classifer is 0.957983.\n"
          ]
        }
      ],
      "source": [
        "# TODO 8\n",
        "#   yhat = ...\n",
        "yhat = logreg.predict(Xts1)\n",
        "accuracy = np.mean(yhat == yts)\n",
        "print('Accuracy of the classifer is %f.' % accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvNzsf0keEU2"
      },
      "source": [
        "## Interpreting the weight vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qijUPhPeEU2"
      },
      "source": [
        "Create a stem plot of the coefficients, `W` in the logistic regression model.  Jse the `plt.stem()` function with the `use_line_collection=True` option.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZBxRcU6qeEU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "18b37564-08ca-49b2-9ceb-cb89fd8e62d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO 9\n",
        "#   W = ...\n",
        "#   plt.stem(...)\n",
        "W = logreg.coef_.ravel()\n",
        "plt.stem(W, use_line_collection=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_5_5IzyeEU2"
      },
      "source": [
        "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.   Below we will use L1 regression to enforce sparsity.  Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lrTp9CwKeEU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46d23fe-159c-4041-ca77-bc372ef4f1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The genes with the largest W[i] are :  ITSN1_N and BRAF_N.\n"
          ]
        }
      ],
      "source": [
        "# TODO 10\n",
        "Warranged = np.argsort(np.abs(W))\n",
        "gene1 = xnames[Warranged[-1]]\n",
        "gene2 = xnames[Warranged[-2]]\n",
        "print('The genes with the largest W[i] are :  %s and %s.' % (gene1, gene2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbGYC5aCeEU2"
      },
      "source": [
        "## Cross Validation\n",
        "\n",
        "To obtain a slightly more accurate result, now perform 10-fold cross validation and measure the average Precision, recall and f1-score.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the mean Precision, recall and f1-score and error rate across all the folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "i7DFOD7ReEU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e64e956-b650-4701-b1d7-f5b51c5b47bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision = 0.989\n",
            "Recall = 0.988\n",
            "F1 = 0.988\n",
            "Error Rate = 0.013\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "# TODO 11\n",
        "Precision = []\n",
        "Recall = []\n",
        "F1 = []\n",
        "Error_rate = []\n",
        "for Itr, Its in kf.split(X):\n",
        "  Xtr = X[Itr,:]\n",
        "  ytr = y[Itr]\n",
        "  Xts = X[Its,:]\n",
        "  yts = y[Its]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  Xtr1 = scaler.fit_transform(Xtr)\n",
        "  Xts1 = scaler.transform(Xts)\n",
        "\n",
        "  logreg = linear_model.LogisticRegression(C=1e5, solver = 'liblinear')\n",
        "  logreg.fit(Xtr1, ytr)\n",
        "\n",
        "  yhat = logreg.predict(Xts1)\n",
        "\n",
        "  measure = precision_recall_fscore_support(yts, yhat, )\n",
        "  precision_i = measure[0]\n",
        "  recall_i = measure[1]\n",
        "  f1_i = measure[2]\n",
        "  Precision.append(precision_i)\n",
        "  Recall.append(recall_i)\n",
        "  F1.append(f1_i)\n",
        "  Error_rate.append(np.mean(yhat !=yts))\n",
        "\n",
        "Precision = np.mean(Precision)\n",
        "Recall = np.mean(Recall)\n",
        "F1 = np.mean(F1)\n",
        "Error_rate = np.mean(Error_rate)\n",
        "print('Precision = %.3f' % Precision)\n",
        "print('Recall = %.3f' % Recall)\n",
        "print('F1 = %.3f' % F1)\n",
        "print('Error Rate = %.3f' % Error_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkYsciaeEU2"
      },
      "source": [
        "## Multi-Class Classification\n",
        "\n",
        "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mvWOlC-BeEU2"
      },
      "outputs": [],
      "source": [
        "# TODO 12\n",
        "#   y = ...\n",
        "response = df1['class'].values\n",
        "resp, y = np.unique(response, return_inverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBQ1qz4PeEU2"
      },
      "source": [
        "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsHCaPYUeEU2"
      },
      "source": [
        "Now perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold. You can use the `confustion_matrix` method in the `sklearn` package.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will represent the fraction of samples where `yhat==j` given `ytrue==i`.  Print the confusion matrix.  You can use the command\n",
        "\n",
        "    print(np.array_str(C, Precision=4, suppress_small=True))\n",
        "    \n",
        "to create a nicely formatted print.  Also print the overall mean and SE of the test accuracy across the folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aHbIfbsieEU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531135e0-7b26-4c9a-c876-9155fa6ff19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.98   0.0148 0.0067 0.     0.     0.     0.     0.    ]\n",
            " [0.0133 0.9704 0.     0.     0.0074 0.     0.0074 0.    ]\n",
            " [0.     0.0074 0.9867 0.     0.0074 0.     0.     0.    ]\n",
            " [0.02   0.     0.     0.9778 0.     0.     0.     0.    ]\n",
            " [0.     0.0074 0.     0.     0.9926 0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
            "Accuracy = 0.987963\n",
            "SE of Accuracy = 0.003665\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# TODO 13\n",
        "\n",
        "\n",
        "\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "C = np.zeros((8,8))\n",
        "Accuracy = []\n",
        "for Ind in kf.split(X):\n",
        "  Itr, Its = Ind\n",
        "  Xtr = X[Itr,:]\n",
        "  ytr = y[Itr]\n",
        "  Xts = X[Its,:]\n",
        "  yts = y[Its]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  Xtr1 = scaler.fit_transform(Xtr)\n",
        "  Xts1 = scaler.transform(Xts)\n",
        "\n",
        "  logreg.fit(Xtr1, ytr)\n",
        "  yhat = logreg.predict(Xts1)\n",
        "  ACC= np.mean(yhat == yts)\n",
        "  Accuracy.append(ACC)\n",
        "  C += confusion_matrix(yts, yhat)\n",
        "\n",
        "\n",
        "C = C / C.sum(axis=1)\n",
        "AccuracyM = np.mean(Accuracy)\n",
        "SE = np.std(Accuracy)/np.sqrt(nfold-1)\n",
        "print(np.array_str(C, precision=4, suppress_small=True))\n",
        "print('Accuracy = %f' % AccuracyM)\n",
        "print('SE of Accuracy = %f' %SE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnbQsoKEeEU2"
      },
      "source": [
        "Re-run the logistic regression on the entire training data and get the weight coefficients.  This should be a 8 x 77 matrix.  Create a stem plot of the first row of this matrix to see the coefficients on each of the genes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GOZP75T5eEU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a423e839-cd69-4347-9106-058aa86d182f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO 14\n",
        "XR = scaler.fit_transform(X)\n",
        "logreg.fit(XR, y)\n",
        "W = logreg.coef_[0,:]\n",
        "plt.stem(W, use_line_collection=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G9ybDu6ueEU2"
      },
      "source": [
        "## L1-Regularization\n",
        "\n",
        "This section is bonus.\n",
        "\n",
        "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, we would expect that the weight coefficients in the logistic regression model should be sparse.  That is, they should be zero on any gene that plays no role in the particular attribute of interest.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term.  Read the `sklearn` [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the `LogisticRegression` class to see how to set the l1-penalty and the inverse regularization strength, `C`.\n",
        "\n",
        "Using the model selection strategies from the [housing demo](../unit05_lasso/demo2_housing.ipynb), use K-fold cross validation to select an appropriate inverse regularization strength.  \n",
        "* Use 10-fold cross validation \n",
        "* You should select around 20 values of `C`.  It is up to you find a good range.\n",
        "* Make appropriate plots and print out to display your results\n",
        "* How does the accuracy compare to the accuracy achieved without regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jkLUvJhmeEU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "cf515503-1de4-4bbd-9ada-247658f7aae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean accuracy rate: 0.002691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO 15\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import sem\n",
        "\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold,shuffle=True)\n",
        "C = np.logspace(-1, 2, 20)\n",
        "AccuracyMatrix = np.zeros((10, 20))\n",
        "for i, Ind in enumerate(kf.split(X)):\n",
        "  Itr, Its = Ind\n",
        "  Xtr = X[Itr,:]\n",
        "  ytr = y[Itr]\n",
        "  Xts = X[Its,:]\n",
        "  yts = y[Its]\n",
        "  Xtr1 = scaler.fit_transform(Xtr)\n",
        "  Xts1 = scaler.transform(Xts)\n",
        "\n",
        "  for j, c in enumerate(C):\n",
        "    logreg = linear_model.LogisticRegression(C=c, penalty='l1', max_iter=100,solver= 'liblinear')\n",
        "    logreg.fit(Xtr1, ytr)\n",
        "    yhat = logreg.predict(Xts1)\n",
        "    AccuracyMatrix[i, j] = np.mean(yhat == yts)\n",
        "\n",
        "\n",
        "MeanAccuracy = np.mean(AccuracyMatrix, axis=0)\n",
        "SEAccuracy = sem(AccuracyMatrix, axis=0)\n",
        "\n",
        "\n",
        "plt.errorbar(np.log10(C), MeanAccuracy, yerr=SEAccuracy, ecolor='r')\n",
        "plt.xlabel('Penalty')\n",
        "plt.ylabel('Accuracy Rate')\n",
        "plt.grid()\n",
        "\n",
        "Coptimal = C[np.where( MeanAccuracy > np.max(MeanAccuracy)-np.min(SEAccuracy))[0][0]]\n",
        "OptimalMeanAccuracy = MeanAccuracy[np.where(C == Coptimal)]\n",
        "OptimalAccuracySE = SEAccuracy[np.where(C == Coptimal)]\n",
        "print('The mean accuracy rate: %f' %OptimalAccuracySE)\n",
        "\n",
        "X1 = scaler.fit_transform(X)\n",
        "logreg = linear_model.LogisticRegression(C=Coptimal, penalty='l1', solver= 'liblinear')\n",
        "logreg.fit(X1, y)\n",
        "W_c = logreg.coef_[0,:]\n",
        "plt.stem(W_c, use_line_collection=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1M4ECqykeEU3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
