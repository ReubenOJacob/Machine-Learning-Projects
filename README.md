# Machine Learning Projetcts:
This repository contains a wide range of labs covering various machine learning topics. 
Through these labs, I have been able to deepen my understanding and implementation of different concepts in machine learning.
Each lab has been thoughtfully designed to provide hands-on experience with different machine learning techniques.

Lab: Neural Networks for Music Classification - I learnt to extract features from audio samples and build a neural network for music classification. I also learnt how to optimize the learning rate of the neural network and use a callback to store the loss and accuracy history during training.

Lab: Nonlinear Least Squares for Modeling Materials - I learnt to set up nonlinear least squares as an unconstrained optimization function, compute the initial parameter estimates for a simple rational model, and implement gradient descent for minimizing the objective. I also learnt how to visualize the convergence of the algorithm.

Lab: Logistic Regression for Gene Expression Data - I learnt to handle missing data, perform multi-class logistic classification, create a confusion matrix, and use L1-regularization for improved estimation in the case of sparse weights (Grad students only). I also learnt how to predict biological characteristics from gene expression data.

Lab: Source Localization for EEG - I learnt to represent responses of multi-channel time-series data using linear models, load data from a pickle file, describe and fit memoryless linear models, and fit linear models with multiple target outputs. I also learnt how to select the optimal delay via cross-validation.

Lab: Transfer Learning with a Pre-Trained Deep Neural Network - I learnt to build a custom image dataset, fine tune the final layers of an existing deep neural network for a new classification task, and load images with a DataGenerator. I also learnt about the concept of transfer learning and how it can produce excellent results on very small datasets with very little computational time.

Lab: Model Order Selection for Neural Data - I learnt to represent neural time-series data in arrays, load data from a pickle file, describe and fit memoryless linear models, and fit linear models with multiple target outputs. I also learnt how to select the optimal delay via cross-validation and perform model selection for performing some simple analysis on real neural signals.

Lab: Hyper-Parameter Optimization with PCA - I learnt to combine PCA with data scaling, compute and visualize PC components, select the number of PCs with K-fold cross validation, implement the multi-stage classifier pipeline in sklearn, and perform automatic parameter search using GridSearchCV in combination with a pipeline.

Lab: Multiple Linear Regression for Robot Calibration - I learnt to use multiple linear regression for calibrating robot control, predict the current draw into one of the joints as a function of the robot motion, and understand how to use multiple linear regression for time series data -- an important concept in dynamical systems such as robotics.

Lab: Simple linear regression - I learnt to load data, plot data, perform simple mathematical manipulations, and fit a simple linear regression model using the Boston housing data set, a widely-used machine learning data set for illustrating basic concepts.

Lab: MNIST Digit Recognition with SVM - I learnt to implement SVM for the classic MNIST problem of digit recognition, select the SVM parameters (C and gamma) via cross-validation, and use the GridSearchCV method to search for parameters with cross-validation. I also learnt how to extend the MNIST dataset by adding a number of non-digit letters and see if the classifier can distinguish the digits from the non-digits.

